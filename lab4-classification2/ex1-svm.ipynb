{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b87ee73-d8c9-4548-b8c2-6c447bc6ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee7c1df-23e7-44e7-8b2f-0f370d9e6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(W, X, Y):\n",
    "    # calculate hinge loss\n",
    "    N = X.shape[0]\n",
    "    distances = 1 - Y * (np.dot(X, W))\n",
    "    distances[distances < 0] = 0  # equivalent to max(0, distance)\n",
    "    hinge_loss = regularization_strength * (np.sum(distances) / N)\n",
    "\n",
    "    # calculate cost\n",
    "    cost = 1 / 2 * np.dot(W, W) + hinge_loss\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51109ce7-deeb-4c1b-a5ca-413fbf7dce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I haven't tested it but this same function should work for\n",
    "# vanilla and mini-batch gradient descent as well\n",
    "def calculate_cost_gradient(W, X_batch, Y_batch):\n",
    "    # if only one example is passed (eg. in case of SGD)\n",
    "    if type(Y_batch) == np.float64:\n",
    "        Y_batch = np.array([Y_batch])\n",
    "        X_batch = np.array([X_batch])  # gives multidimensional array\n",
    "\n",
    "    distance = 1 - (Y_batch * np.dot(X_batch, W))\n",
    "    dw = np.zeros(len(W))\n",
    "    \n",
    "    distance = np.array([distance])\n",
    "\n",
    "    for ind, d in enumerate(distance):\n",
    "        if max(0, d) == 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (regularization_strength * Y_batch * X_batch[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/1  # average\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a02ad4de-c2a8-499d-b2cc-e6a1c6b1f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(features, outputs):\n",
    "    max_epochs = 5000\n",
    "    weights = np.zeros(features.shape[1])\n",
    "    nth = 0\n",
    "    prev_cost = float(\"inf\")\n",
    "    cost_threshold = 0.01  # in percent\n",
    "    # stochastic gradient descent\n",
    "    for epoch in range(1, max_epochs):\n",
    "        # shuffle to prevent repeating update cycles\n",
    "        X, Y = shuffle(features, outputs)\n",
    "        for ind, x in enumerate(X):\n",
    "            ascent = calculate_cost_gradient(weights, x, Y[ind])\n",
    "            weights = weights - (learning_rate * ascent)\n",
    "\n",
    "        # convergence check on 2^nth epoch\n",
    "        if epoch == 2 ** nth or epoch == max_epochs - 1:\n",
    "            cost = compute_cost(weights, features, outputs)\n",
    "            print(\"Epoch is: {} and Cost is: {}\".format(epoch, cost))\n",
    "            # stoppage criterion\n",
    "            if abs(prev_cost - cost) < cost_threshold * prev_cost:\n",
    "                return weights\n",
    "            prev_cost = cost\n",
    "            nth += 1\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cffa470e-86f9-4cf7-88f3-c36e337ac151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading dataset...\n",
      "splitting dataset into train and test sets...\n",
      "training started...\n",
      "Epoch is: 1 and Cost is: 4974.547821751557\n",
      "Epoch is: 2 and Cost is: 4967.221346024681\n",
      "training finished.\n",
      "weights are: [1.28330157 1.28330157]\n",
      "testing the model...\n",
      "accuracy on test dataset: 0.485\n",
      "recall on test dataset: 1.0\n",
      "precision on test dataset: 0.485\n"
     ]
    }
   ],
   "source": [
    "# set hyper-parameters and call init\n",
    "regularization_strength = 10000\n",
    "learning_rate = 0.000001\n",
    "\n",
    "print(\"reading dataset...\")\n",
    "# read data in pandas (pd) data frame\n",
    "X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=42)\n",
    "\n",
    "# normalize data for better convergence and to prevent overflow\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# split data into train and test set\n",
    "print(\"splitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the model\n",
    "print(\"training started...\")\n",
    "W = sgd(X_train, y_train)\n",
    "print(\"training finished.\")\n",
    "print(\"weights are: {}\".format(W))\n",
    "\n",
    "# testing the model\n",
    "print(\"testing the model...\")\n",
    "y_train_predicted = np.array([])\n",
    "for i in range(X_train.shape[0]):\n",
    "    yp = np.sign(np.dot(X_train[i], W))\n",
    "    y_train_predicted = np.append(y_train_predicted, yp)\n",
    "\n",
    "y_test_predicted = np.array([])\n",
    "for i in range(X_test.shape[0]):\n",
    "    yp = np.sign(np.dot(X_test[i], W))\n",
    "    y_test_predicted = np.append(y_test_predicted, yp)\n",
    "\n",
    "print(\"accuracy on test dataset: {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"recall on test dataset: {}\".format(recall_score(y_test, y_test_predicted)))\n",
    "print(\"precision on test dataset: {}\".format(precision_score(y_test, y_test_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f088975a-e2c1-4a24-bd5b-f6e6abeb0f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
